{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all the loads data with its necessary weather data, format the datetime columns, and add new timeseries features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_dict = joblib.load('weather_dict.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CAPITL': ('kalb', 'Capital', 'Albany'),\n",
       " 'CENTRL': ('ksyr', 'Central', 'Syracuse'),\n",
       " 'DUNWOD': ('klga', 'Dunwoodie', 'Yonkers'),\n",
       " 'GENESE': ('kroc', 'Genese', 'Rochester'),\n",
       " 'HUD VL': ('kpou', 'Hudson Valley', 'Poughkeepsie'),\n",
       " 'LONGIL': ('kjfk', 'Long Island', 'NYC'),\n",
       " 'MHK VL': ('krme', 'Mohawk Valley', 'Utica'),\n",
       " 'MILLWD': ('klga', 'Millwood', 'Yonkers'),\n",
       " 'N.Y.C.': ('kjfk', 'NYC', 'NYC'),\n",
       " 'NORTH': ('kpbg', 'North', 'Plattsburgh'),\n",
       " 'WEST': ('kbuf', 'West', 'Buffalo')}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all the region data from 2012-2015\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Format datetime columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def format_datetime(weather, loads):\n",
    "    #Format datetime columns:\n",
    "    weather['date'] = weather.dateutc.apply(lambda x: pd.to_datetime(x).date())\n",
    "    weather['timeest'] = weather.timeest.apply(lambda x: pd.to_datetime(x).time())\n",
    "    foo = weather[['date', 'timeest']].astype(str)\n",
    "    weather['timestamp'] = pd.to_datetime(foo['date'] + ' ' + foo['timeest'])\n",
    "    loads['timestamp'] = loads.timestamp.apply(lambda x: pd.to_datetime(x))\n",
    "    return weather, loads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Add weather data to loads data\n",
    "Weather data is on hourly intervals, loads data is every five minutes. This is a function to merge based on the nearest datetime, using K-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def find_nearest(group, match, groupname):\n",
    "    nbrs = NearestNeighbors(1).fit(match['timestamp'].values[:, None])\n",
    "    dist, ind = nbrs.kneighbors(group['timestamp'].values[:, None])\n",
    "\n",
    "    group['nearesttime'] = match['timestamp'].values[ind.ravel()]\n",
    "    return group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new features based on the timeseries. These first features come from [Barta et al. 2015](http://arxiv.org/pdf/1506.06972.pdf), who applied probabalistic modeling techniques (such as Gradient-Boosting Regression) to forecast electricity prices:\n",
    "\n",
    "    `dow`: day of the week (integer 0-6)\n",
    "    `doy`: day of the year (integer 0-365)\n",
    "    `day`: day of the month (integer 1-31)\n",
    "    `woy`: week of the year (integer 1-52)\n",
    "    `month`: month of the year (integer 1-12)\n",
    "    `hour`: hour of the day (integer 0-23)\n",
    "    `minute`: minute of the day (integer 0-1339)\n",
    "    \n",
    "    `t_m24`: load value from 24 hours earlier\n",
    "    `t_m48`: load value from 48 hours earlier\n",
    "    `tdif`: difference between load and t_m24\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#datetime value of one day\n",
    "pday = pd.Timedelta('1 day')\n",
    "\n",
    "def get_prev_days(x, n_days):\n",
    "    '''Take a datetime (x) in the 'full' dataframe, and outputs the load value n_days before that datetime'''\n",
    "    try:\n",
    "        lo = full[full.timestamp == x - n_days*pday].load.values[0]\n",
    "    except:\n",
    "        lo = full[full.timestamp == x].load.values[0]\n",
    "    return lo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_time_features(df):\n",
    "    full = df.copy()\n",
    "    full['dow'] = full.timestamp.apply(lambda x: x.dayofweek)\n",
    "    full['doy'] = full.timestamp.apply(lambda x: x.dayofyear)\n",
    "    full['day'] = full.timestamp.apply(lambda x: x.day)\n",
    "    full['month'] = full.timestamp.apply(lambda x: x.month)\n",
    "    full['year'] = full.timestamp.apply(lambda x: x.year)\n",
    "    full['hour'] = full.timestamp.apply(lambda x: x.hour)\n",
    "    full['minute'] = full.timestamp.apply(lambda x: x.hour*60 + x.minute)\n",
    "\n",
    "    full['t_m24'] = full.timestamp.apply(get_prev_days, args=(1,))\n",
    "    full['t_m48'] = full.timestamp.apply(get_prev_days, args=(2,))\n",
    "    full['tdif'] = full['load'] - full['t_m24']\n",
    "    return full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run this for every subset of NYS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k = weather_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for region in k:\n",
    "    \n",
    "    place = weather_dict[region][1].lower().replace(' ','')\n",
    "    airport = weather_dict[region][0]\n",
    "\n",
    "    #load in the data\n",
    "    loads = pd.read_csv('../data/nyiso/all/{0}.csv'.format(place))\n",
    "    weather = pd.read_csv('../data/wunderground/{0}_all.csv'.format(airport))\n",
    "\n",
    "    #remove loose headers\n",
    "    weather = weather[weather.winddirection != 'winddirection']\n",
    "    \n",
    "    #format datetime columns\n",
    "    weather, loads = format_datetime(weather, loads)\n",
    "\n",
    "    #combine using KNN\n",
    "    loads = find_nearest(loads,weather,'timestamp')\n",
    "    full = loads.merge(weather, left_on='nearesttime', right_on='timestamp')\n",
    "\n",
    "    #Remove and rename redundant columns \n",
    "    full = full[['timestamp_x', 'load', 'nearesttime', 'temperaturef', \\\n",
    "                'dewpointf', 'humidity', 'sealevelpressurein', 'winddirection', 'windspeedmph', \\\n",
    "                'precipitationin']].rename(columns={'timestamp_x': 'timestamp', 'nearesttime':'weathertime'})\n",
    "\n",
    "    #Create features\n",
    "    full = add_time_features(full)\n",
    "\n",
    "    #Export to csv\n",
    "    full.to_csv('full_{0}_features.csv'.format(place), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#datetime value of one day\n",
    "phour = pd.Timedelta('1 hour')\n",
    "\n",
    "def get_prev_hours(x, n_hours):\n",
    "    '''Take a datetime (x) in the 'full' dataframe, and outputs the load value n_days before that datetime'''\n",
    "    try:\n",
    "        lo = full[full.timestamp == x - n_hours*phour].load.values[0]\n",
    "    except:\n",
    "        lo = full[full.timestamp == x].load.values[0]\n",
    "    return lo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for region in k:\n",
    "    place = weather_dict[region][1].lower().replace(' ','')\n",
    "    airport = weather_dict[region][0]\n",
    "    \n",
    "    full = pd.read_csv('full_{0}_features.csv'.format(place))\n",
    "    \n",
    "    full['t_m1'] = full.timestamp.apply(get_prev_hours, args=(1,))\n",
    "    \n",
    "    full.to_csv('full_{0}_features.csv'.format(place), index=False)\n",
    "    \n",
    "    print \"%s done\" % place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
